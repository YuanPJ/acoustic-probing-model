data:
  corpus:                                 
    name: 'Librispeech'                   # Specify corpus
    path: 'save/LibriSpeech'          # Path to raw LibriSpeech dataset
    train_split: ['train-clean-100']      # Name of data splits to be used as training set
    dev_split: ['dev-clean']              # Name of data splits to be used as validation set
    bucketing: False                       # Enable/Disable bucketing 
    batch_size: 64
  audio:
    num_freq: 1025
    num_mels: 80
    frame_length_ms: 50
    frame_shift_ms: 12.5
    preemphasis_coeff: 0.97
    sample_rate: 16000
    use_linear: False                      ### Return Linear spectrogram
    # augmentation
    noise:
      path: 'save/musan'
      #genre:
      #  music: [[5, 15], [1,1]]
      #  noise: [[0, 15], [1,1]]
      #  speech: [[13, 20], [3,7]]
    snr_range: [-1]
    time_stretch_range: [1.0, 1.0]
    inverse_prob: 0.0
  text:
    mode: 'subword'                       # 'character'/'word'/'subword'
    vocab_file: 'tests/sample_data/subword.model'

hparas:                                   # Experiment hyper-parameters
  valid_step: 200000
  curriculum: 0
  max_step: 240001
  tf_start: 1.0
  tf_end: 1.0
  tf_step: 500000
  grad_clip: 'inf'
  optimizer:
    type: 'Adam'
    lr: 0.0001
  lr_scheduler:
    type: 'reduce_lr_on_plateau'                   # 'fixed'/'warmup'/'decay'/'reduce_lr_on_plateau'
  freq_loss_type: 'l1'                         # 'l1'/'mse'
  differential_loss: False
  emphasize_linear_low: False
  
model:                                    # Model architecture
  delta: 2
  ctc_weight: 1.0                         # Weight for CTC loss
  encoder:
    cnn:                             # 4x reduction on time feature extraction
      type: 'vgg'
    module: 'LSTM'                        # 'LSTM'/'GRU'/'Transformer'
    bidirection: True
    dim: [320,320,320,320,320]
    dropout: [0,0,0,0,0]
    layer_norm: [False,False,False,False,False]
    proj: [True,True,True,True,True]      # Linear projection + Tanh after each rnn layer
    sample_rate: [1,1,1,1,1]
    sample_style: 'drop'                  # 'drop'/'concat'
  attention:
    mode: 'loc'                           # 'dot'/'loc'
    dim: 300
    num_head: 1
    v_proj: False                         # if False and num_head>1, encoder state will be duplicated for each head
    temperature: 1                        # scaling factor for attention
    loc_kernel_size: 100                  # just for mode=='loc'
    loc_kernel_num: 10                    # just for mode=='loc'
  decoder:
    module: 'LSTM'                        # 'LSTM'/'GRU'/'Transformer'
    dim: 320
    layer: 1
    dropout: 0
id_net:
    type: 'netvlad'
    loss_fn: "softmax"
    time_dim: 256
    spkr_dim: 256
    resnet_config:
      planes: [48, 96, 128, 256, 512]
    netvlad_config:
      num_clusters: 8
tts:
  # type: 'highway'
  layer_num: -2
  num_layers: 4
    # encoder:
    #   layer_num: 4
    #   enc_embed_dim: 320
  type: 'None'
  #decoder:
  #  n_frames_per_step: 5
  #  prenet_dim: 128
  #  prenet_dropout: 0.5
  #  query_rnn_dim: 1024
  #  dec_rnn_dim: 1024
  #  query_dropout: 0.1
  #  dec_dropout: 0.1
  #  attn_dim: 256
  #  n_location_filters: 32
  #  location_kernel_size: 31
  #  loc_aware: True
  #  use_summed_weights: True
  #  drop_dec_in: 0.0
  #postnet:
  #  postnet_embed_dim: 512
  #  postnet_kernel_size: 5
  #  postnet_n_conv: 5
  #  postnet_dropout: 0.5
